{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b4f22f1",
   "metadata": {},
   "source": [
    "## In this notebook we'll be using TF-IDF to predict which category a certain review belongs to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343643c",
   "metadata": {},
   "source": [
    "### But first, a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e531b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"Juan likes webscraping, Mathilde likes webscraping, Ilkay hates webscraping\",\n",
    "    \"Apple is announcing new iphone tomorrow\",\n",
    "    \"Tesla is announcing new model-3 tomorrow\",\n",
    "    \"Google is announcing new pixel-6 tomorrow\",\n",
    "    \"Microsoft is announcing new bing version tomorrow\",\n",
    "    \"Amazon is announcing new warehouse tomorrow\",\n",
    "    \"I am eating pierogi and you are eating joloff rice\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb8dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = TfidfVectorizer()\n",
    "v.fit(corpus)\n",
    "transform_output = v.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481dda80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'juan': 14,\n",
       " 'likes': 15,\n",
       " 'webscraping': 27,\n",
       " 'mathilde': 16,\n",
       " 'ilkay': 10,\n",
       " 'hates': 9,\n",
       " 'apple': 4,\n",
       " 'is': 12,\n",
       " 'announcing': 3,\n",
       " 'new': 19,\n",
       " 'iphone': 11,\n",
       " 'tomorrow': 24,\n",
       " 'tesla': 23,\n",
       " 'model': 18,\n",
       " 'google': 8,\n",
       " 'pixel': 21,\n",
       " 'microsoft': 17,\n",
       " 'bing': 6,\n",
       " 'version': 25,\n",
       " 'amazon': 1,\n",
       " 'warehouse': 26,\n",
       " 'am': 0,\n",
       " 'eating': 7,\n",
       " 'pierogi': 20,\n",
       " 'and': 2,\n",
       " 'you': 28,\n",
       " 'are': 5,\n",
       " 'joloff': 13,\n",
       " 'rice': 22}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "763da561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am : 2.386294361119891\n",
      "amazon : 2.386294361119891\n",
      "and : 2.386294361119891\n",
      "announcing : 1.2876820724517808\n",
      "apple : 2.386294361119891\n",
      "are : 2.386294361119891\n",
      "bing : 2.386294361119891\n",
      "eating : 2.386294361119891\n",
      "google : 2.386294361119891\n",
      "hates : 2.386294361119891\n",
      "ilkay : 2.386294361119891\n",
      "iphone : 2.386294361119891\n",
      "is : 1.2876820724517808\n",
      "joloff : 2.386294361119891\n",
      "juan : 2.386294361119891\n",
      "likes : 2.386294361119891\n",
      "mathilde : 2.386294361119891\n",
      "microsoft : 2.386294361119891\n",
      "model : 2.386294361119891\n",
      "new : 1.2876820724517808\n",
      "pierogi : 2.386294361119891\n",
      "pixel : 2.386294361119891\n",
      "rice : 2.386294361119891\n",
      "tesla : 2.386294361119891\n",
      "tomorrow : 1.2876820724517808\n",
      "version : 2.386294361119891\n",
      "warehouse : 2.386294361119891\n",
      "webscraping : 2.386294361119891\n",
      "you : 2.386294361119891\n"
     ]
    }
   ],
   "source": [
    "all_feature_names = v.get_feature_names_out()\n",
    "\n",
    "for word in all_feature_names:\n",
    "    \n",
    "    \n",
    "    indx = v.vocabulary_.get(word)\n",
    "    \n",
    "    \n",
    "    idf_score = v.idf_[indx]\n",
    "    \n",
    "    print(f\"{word} : {idf_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e936d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.24253563 0.24253563 0.\n",
      "  0.         0.         0.24253563 0.48507125 0.24253563 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.72760688 0.        ]\n",
      " [0.         0.         0.         0.30333014 0.56212245 0.\n",
      "  0.         0.         0.         0.         0.         0.56212245\n",
      "  0.30333014 0.         0.         0.         0.         0.\n",
      "  0.         0.30333014 0.         0.         0.         0.\n",
      "  0.30333014 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.30333014 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.30333014 0.         0.         0.         0.         0.\n",
      "  0.56212245 0.30333014 0.         0.         0.         0.56212245\n",
      "  0.30333014 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.30333014 0.         0.\n",
      "  0.         0.         0.56212245 0.         0.         0.\n",
      "  0.30333014 0.         0.         0.         0.         0.\n",
      "  0.         0.30333014 0.         0.56212245 0.         0.\n",
      "  0.30333014 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.26441778 0.         0.\n",
      "  0.49001121 0.         0.         0.         0.         0.\n",
      "  0.26441778 0.         0.         0.         0.         0.49001121\n",
      "  0.         0.26441778 0.         0.         0.         0.\n",
      "  0.26441778 0.49001121 0.         0.         0.        ]\n",
      " [0.         0.56212245 0.         0.30333014 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.30333014 0.         0.         0.         0.         0.\n",
      "  0.         0.30333014 0.         0.         0.         0.\n",
      "  0.30333014 0.         0.56212245 0.         0.        ]\n",
      " [0.30151134 0.         0.30151134 0.         0.         0.30151134\n",
      "  0.         0.60302269 0.         0.         0.         0.\n",
      "  0.         0.30151134 0.         0.         0.         0.\n",
      "  0.         0.         0.30151134 0.         0.30151134 0.\n",
      "  0.         0.         0.         0.         0.30151134]]\n"
     ]
    }
   ],
   "source": [
    "print(transform_output.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd85a82",
   "metadata": {},
   "source": [
    "## E-commerce use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "752c41ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household\n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household\n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics\n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories\n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Ecommerce_data.csv\")\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5166da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Household                 6000\n",
       "Electronics               6000\n",
       "Clothing & Accessories    6000\n",
       "Books                     6000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01283a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urban Ladder Eisner Low Back Study-Office Comp...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contrast living Wooden Decorative Box,Painted ...</td>\n",
       "      <td>Household</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IO Crest SY-PCI40010 PCI RAID Host Controller ...</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISAKAA Baby Socks from Just Born to 8 Years- P...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Designer Women's Art Mysore Silk Saree ...</td>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                   label  \\\n",
       "0  Urban Ladder Eisner Low Back Study-Office Comp...               Household   \n",
       "1  Contrast living Wooden Decorative Box,Painted ...               Household   \n",
       "2  IO Crest SY-PCI40010 PCI RAID Host Controller ...             Electronics   \n",
       "3  ISAKAA Baby Socks from Just Born to 8 Years- P...  Clothing & Accessories   \n",
       "4  Indira Designer Women's Art Mysore Silk Saree ...  Clothing & Accessories   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          2  \n",
       "3          3  \n",
       "4          3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_num'] = df['label'].map({\n",
    "    'Household' : 0, \n",
    "    'Books': 1, \n",
    "    'Electronics': 2, \n",
    "    'Clothing & Accessories': 3\n",
    "})\n",
    "\n",
    "#map function changes strings into intergers\n",
    "\n",
    "#checking the results \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bada422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.Text, \n",
    "    df.label_num, \n",
    "    test_size=0.2, \n",
    "    random_state=2022,\n",
    "    stratify=df.label_num #stratify make sure to have the same proporcion in lables \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "348e0a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4800\n",
       "2    4800\n",
       "3    4800\n",
       "1    4800\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09b7f692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1200\n",
       "2    1200\n",
       "3    1200\n",
       "1    1200\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ed8be",
   "metadata": {},
   "source": [
    "## First Model: KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eac9ed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1200\n",
      "           1       0.97      0.95      0.96      1200\n",
      "           2       0.97      0.97      0.97      1200\n",
      "           3       0.97      0.98      0.97      1200\n",
      "\n",
      "    accuracy                           0.96      4800\n",
      "   macro avg       0.96      0.96      0.96      4800\n",
      "weighted avg       0.96      0.96      0.96      4800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aguil\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('KNN', KNeighborsClassifier())         \n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adbf8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test= ['this product is not working as it is described in the website. The quality is really bad and I did not get a refound']\n",
    "sample_test_cv = v.transform(sample_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b6bc558",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8016\\1472220183.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_test_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2099\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"The TF-IDF vectorizer is not fitted\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2101\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \"\"\"\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    " clf.predict(sample_test_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791faa8",
   "metadata": {},
   "source": [
    "## Second model: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "127e612a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1200\n",
      "           1       0.98      0.92      0.95      1200\n",
      "           2       0.97      0.97      0.97      1200\n",
      "           3       0.97      0.99      0.98      1200\n",
      "\n",
      "    accuracy                           0.96      4800\n",
      "   macro avg       0.96      0.96      0.96      4800\n",
      "weighted avg       0.96      0.96      0.96      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('Multi NB', MultinomialNB())         \n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0554dead",
   "metadata": {},
   "source": [
    "## Third model: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8acce278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1200\n",
      "           1       0.97      0.98      0.98      1200\n",
      "           2       0.98      0.97      0.97      1200\n",
      "           3       0.98      0.99      0.98      1200\n",
      "\n",
      "    accuracy                           0.97      4800\n",
      "   macro avg       0.97      0.97      0.97      4800\n",
      "weighted avg       0.97      0.97      0.97      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = Pipeline([\n",
    "     ('vectorizer_tfidf',TfidfVectorizer()),    \n",
    "     ('Random Forest', RandomForestClassifier())         \n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b8ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
